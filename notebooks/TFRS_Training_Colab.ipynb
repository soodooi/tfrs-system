{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRS 推荐系统训练笔记本\n",
    "\n",
    "本笔记本用于在 Google Colab 上训练 TensorFlow Recommenders 模型\n",
    "\n",
    "## 使用步骤\n",
    "1. 在 Colab 中打开此笔记本\n",
    "2. 运行时 → 更改运行时类型 → 选择 GPU\n",
    "3. 点击 \"运行全部\"\n",
    "4. 等待训练完成（约 2-4 小时）\n",
    "5. 下载训练好的模型\n",
    "\n",
    "**注意**: 本笔记本仅用于学习和研究目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查 GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装依赖\n",
    "!pip install -q tensorflow==2.15.0\n",
    "!pip install -q tensorflow-recommenders==0.7.3\n",
    "!pip install -q pandas numpy scikit-learn\n",
    "!pip install -q requests beautifulsoup4\n",
    "!pip install -q tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Text\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"TFRS version: {tfrs.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据准备\n",
    "\n",
    "### 选项 A: 使用公开数据集（推荐）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 MovieLens 数据集作为示例\n",
    "# 实际使用时替换为您的数据\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# 加载 MovieLens 数据集\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "\n",
    "# 查看数据\n",
    "for x in ratings.take(1):\n",
    "    print(f\"User: {x['user_id']}\")\n",
    "    print(f\"Movie: {x['movie_id']}\")\n",
    "    print(f\"Rating: {x['user_rating']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选项 B: 生成合成数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成合成数据用于测试\n",
    "def generate_synthetic_data(n_users=10000, n_items=1000, n_interactions=100000):\n",
    "    \"\"\"\n",
    "    生成合成推荐数据\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # 生成用户ID（幂律分布）\n",
    "    user_ids = np.random.zipf(1.5, n_interactions) % n_users\n",
    "    \n",
    "    # 生成商品ID（长尾分布）\n",
    "    item_ids = np.random.zipf(1.3, n_interactions) % n_items\n",
    "    \n",
    "    # 生成评分\n",
    "    ratings = np.random.randint(1, 6, n_interactions)\n",
    "    \n",
    "    # 生成时间戳\n",
    "    timestamps = np.random.randint(1640000000, 1700000000, n_interactions)\n",
    "    \n",
    "    # 创建 DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'user_id': [f'user_{i}' for i in user_ids],\n",
    "        'item_id': [f'item_{i}' for i in item_ids],\n",
    "        'rating': ratings,\n",
    "        'timestamp': timestamps\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 生成数据\n",
    "df = generate_synthetic_data()\n",
    "print(f\"Generated {len(df)} interactions\")\n",
    "print(df.head())\n",
    "\n",
    "# 转换为 TensorFlow Dataset\n",
    "ratings = tf.data.Dataset.from_tensor_slices(dict(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取唯一的用户和商品ID\n",
    "user_ids = ratings.map(lambda x: x['user_id'])\n",
    "item_ids = ratings.map(lambda x: x['item_id'])\n",
    "\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids.batch(1000))))\n",
    "unique_item_ids = np.unique(np.concatenate(list(item_ids.batch(1000))))\n",
    "\n",
    "print(f\"Unique users: {len(unique_user_ids)}\")\n",
    "print(f\"Unique items: {len(unique_item_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train_size = int(0.8 * len(df))\n",
    "train = shuffled.take(train_size)\n",
    "test = shuffled.skip(train_size).take(len(df) - train_size)\n",
    "\n",
    "print(f\"Train size: {train_size}\")\n",
    "print(f\"Test size: {len(df) - train_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 构建双塔模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "    \"\"\"用户塔模型\"\"\"\n",
    "    \n",
    "    def __init__(self, unique_user_ids, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 用户ID嵌入\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_user_ids,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                len(unique_user_ids) + 1,\n",
    "                embedding_dim\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # 深度网络\n",
    "        self.dense_layers = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "        ])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        user_embedding = self.user_embedding(inputs['user_id'])\n",
    "        return self.dense_layers(user_embedding)\n",
    "\n",
    "\n",
    "class ItemModel(tf.keras.Model):\n",
    "    \"\"\"商品塔模型\"\"\"\n",
    "    \n",
    "    def __init__(self, unique_item_ids, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 商品ID嵌入\n",
    "        self.item_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_item_ids,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                len(unique_item_ids) + 1,\n",
    "                embedding_dim\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # 深度网络\n",
    "        self.dense_layers = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "        ])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        item_embedding = self.item_embedding(inputs['item_id'])\n",
    "        return self.dense_layers(item_embedding)\n",
    "\n",
    "\n",
    "class TwoTowerModel(tfrs.Model):\n",
    "    \"\"\"双塔推荐模型\"\"\"\n",
    "    \n",
    "    def __init__(self, user_model, item_model, items_dataset):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_model = user_model\n",
    "        self.item_model = item_model\n",
    "        \n",
    "        # 检索任务\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=items_dataset.batch(128).map(\n",
    "                    lambda x: (x['item_id'], self.item_model(x))\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def compute_loss(self, features, training=False):\n",
    "        user_embeddings = self.user_model(features)\n",
    "        item_embeddings = self.item_model(features)\n",
    "        return self.task(user_embeddings, item_embeddings)\n",
    "\n",
    "print(\"Model classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型实例\n",
    "user_model = UserModel(unique_user_ids)\n",
    "item_model = ItemModel(unique_item_ids)\n",
    "\n",
    "# 创建商品数据集（用于候选生成）\n",
    "items_dataset = ratings.map(lambda x: {'item_id': x['item_id']})\n",
    "\n",
    "# 创建双塔模型\n",
    "model = TwoTowerModel(user_model, item_model, items_dataset)\n",
    "\n",
    "print(\"Model created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译模型\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "# 配置回调\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_factorized_top_k/top_100_categorical_accuracy',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./checkpoints/model_{epoch:02d}',\n",
    "        save_weights_only=False,\n",
    "        save_freq='epoch'\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Model compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "history = model.fit(\n",
    "    train.batch(4096),\n",
    "    validation_data=test.batch(4096),\n",
    "    epochs=10,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估模型\n",
    "metrics = model.evaluate(test.batch(4096), return_dict=True)\n",
    "\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化训练历史\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['factorized_top_k/top_100_categorical_accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_factorized_top_k/top_100_categorical_accuracy'], label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Top-100 Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 测试推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建推荐索引\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index_from_dataset(\n",
    "    items_dataset.batch(100).map(\n",
    "        lambda x: (x['item_id'], model.item_model(x))\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Index created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为测试用户生成推荐\n",
    "test_user_id = unique_user_ids[0]\n",
    "_, recommendations = index(tf.constant([test_user_id]))\n",
    "\n",
    "print(f\"\\nTop 10 recommendations for {test_user_id}:\")\n",
    "for i, item_id in enumerate(recommendations[0, :10].numpy()):\n",
    "    print(f\"{i+1}. {item_id.decode('utf-8')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 导出模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存完整模型\n",
    "model_path = './saved_models/two_tower'\n",
    "tf.saved_model.save(model, model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# 保存索引\n",
    "index_path = './saved_models/index'\n",
    "tf.saved_model.save(index, index_path)\n",
    "print(f\"Index saved to {index_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 压缩模型文件\n",
    "!zip -r saved_models.zip ./saved_models\n",
    "print(\"Model compressed to saved_models.zip\")\n",
    "print(\"\\n下载此文件并上传到 Railway 进行部署\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 下载模型\n",
    "\n",
    "运行下面的代码下载训练好的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# 下载压缩的模型文件\n",
    "files.download('saved_models.zip')\n",
    "\n",
    "print(\"\\n模型已下载！\")\n",
    "print(\"\\n下一步:\")\n",
    "print(\"1. 解压 saved_models.zip\")\n",
    "print(\"2. 将 saved_models 文件夹上传到项目的 models/ 目录\")\n",
    "print(\"3. 部署到 Railway\")\n",
    "print(\"4. 测试 API: curl https://your-app.railway.app/api/recommend/user_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完成！\n",
    "\n",
    "恭喜！您已经成功训练了一个 TFRS 推荐模型。\n",
    "\n",
    "### 下一步\n",
    "1. 下载训练好的模型\n",
    "2. 上传到 GitHub 仓库\n",
    "3. 在 Railway 部署\n",
    "4. 测试 API\n",
    "\n",
    "### 改进建议\n",
    "- 使用真实数据替换合成数据\n",
    "- 添加更多特征（用户年龄、商品类别等）\n",
    "- 尝试不同的模型架构\n",
    "- 调整超参数\n",
    "- 实现 A/B 测试"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}