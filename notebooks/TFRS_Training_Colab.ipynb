{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbA5cphAlKhB"
      },
      "source": [
        "# TFRS 推荐系统训练笔记本\n",
        "\n",
        "本笔记本用于在 Google Colab 上训练 TensorFlow Recommenders 模型\n",
        "\n",
        "## 使用步骤\n",
        "1. 在 Colab 中打开此笔记本\n",
        "2. 运行时 → 更改运行时类型 → 选择 GPU\n",
        "3. 点击 \"运行全部\"\n",
        "4. 等待训练完成（约 2-4 小时）\n",
        "5. 下载训练好的模型\n",
        "\n",
        "**注意**: 本笔记本仅用于学习和研究目的"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaidAW-KlKhE"
      },
      "source": [
        "## 1. 环境设置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WVXALSpDlKhF",
        "outputId": "d2adcb25-55fd-430d-c164-8b89da2b80a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan 17 10:52:40 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P0             27W /   70W |     110MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# 检查 GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9RAvCBhzlKhG",
        "outputId": "2ab9f3b4-9bfe-4713-daba-84d7b3873dc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.15.0 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.15.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# 安装依赖\n",
        "!pip install tensorflow==2.17.0\n",
        "!pip install tensorflow-recommenders\n",
        "!pip install -q pandas numpy scikit-learn\n",
        "!pip install -q requests beautifulsoup4\n",
        "!pip install -q tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hA3TtlXylKhG",
        "outputId": "d2b780a7-f6c6-4475-bbb9-14c73efac9be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "TFRS version: v0.7.3\n",
            "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "# 导入库\n",
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, Text\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"TFRS version: {tfrs.__version__}\")\n",
        "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBA_rnCGlKhG"
      },
      "source": [
        "## 2. 数据准备\n",
        "\n",
        "### 选项 A: 使用公开数据集（推荐）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "z6_Y6ljnlKhH",
        "outputId": "5939a0d8-1540-413c-cd2f-3bce47b32fba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: b'138'\n",
            "Movie: b'357'\n",
            "Rating: 4.0\n"
          ]
        }
      ],
      "source": [
        "# 使用 MovieLens 数据集作为示例\n",
        "# 实际使用时替换为您的数据\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# 加载 MovieLens 数据集\n",
        "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
        "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
        "\n",
        "# 查看数据\n",
        "for x in ratings.take(1):\n",
        "    print(f\"User: {x['user_id']}\")\n",
        "    print(f\"Movie: {x['movie_id']}\")\n",
        "    print(f\"Rating: {x['user_rating']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqNud996lKhH"
      },
      "source": [
        "### 选项 B: 生成合成数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8j7D-FY7lKhH",
        "outputId": "7d651771-3950-42ee-e8c1-d6283a3eae68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 100000 interactions\n",
            "   user_id  item_id  rating   timestamp\n",
            "0  user_13   item_9       1  1671052518\n",
            "1   user_1   item_1       4  1652334631\n",
            "2   user_1   item_2       2  1646200540\n",
            "3   user_1   item_2       1  1671625773\n",
            "4  user_35  item_23       2  1642221864\n"
          ]
        }
      ],
      "source": [
        "# 生成合成数据用于测试\n",
        "def generate_synthetic_data(n_users=10000, n_items=1000, n_interactions=100000):\n",
        "    \"\"\"\n",
        "    生成合成推荐数据\n",
        "    \"\"\"\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # 生成用户ID（幂律分布）\n",
        "    user_ids = np.random.zipf(1.5, n_interactions) % n_users\n",
        "\n",
        "    # 生成商品ID（长尾分布）\n",
        "    item_ids = np.random.zipf(1.3, n_interactions) % n_items\n",
        "\n",
        "    # 生成评分\n",
        "    ratings = np.random.randint(1, 6, n_interactions)\n",
        "\n",
        "    # 生成时间戳\n",
        "    timestamps = np.random.randint(1640000000, 1700000000, n_interactions)\n",
        "\n",
        "    # 创建 DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'user_id': [f'user_{i}' for i in user_ids],\n",
        "        'item_id': [f'item_{i}' for i in item_ids],\n",
        "        'rating': ratings,\n",
        "        'timestamp': timestamps\n",
        "    })\n",
        "\n",
        "    return df\n",
        "\n",
        "# 生成数据\n",
        "df = generate_synthetic_data()\n",
        "print(f\"Generated {len(df)} interactions\")\n",
        "print(df.head())\n",
        "\n",
        "# 转换为 TensorFlow Dataset\n",
        "ratings = tf.data.Dataset.from_tensor_slices(dict(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A62E1Q7ClKhI"
      },
      "source": [
        "## 3. 数据预处理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KfzkqF-ilKhI",
        "outputId": "a9432e77-b130-49d9-b908-76c44b1ef888",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique users: 2883\n",
            "Unique items: 1000\n"
          ]
        }
      ],
      "source": [
        "# 提取唯一的用户和商品ID\n",
        "user_ids = ratings.map(lambda x: x['user_id'])\n",
        "item_ids = ratings.map(lambda x: x['item_id'])\n",
        "\n",
        "unique_user_ids = np.unique(np.concatenate(list(user_ids.batch(1000))))\n",
        "unique_item_ids = np.unique(np.concatenate(list(item_ids.batch(1000))))\n",
        "\n",
        "print(f\"Unique users: {len(unique_user_ids)}\")\n",
        "print(f\"Unique items: {len(unique_item_ids)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5A4sqYFXlKhI",
        "outputId": "4bfd7aa8-9c40-4d42-e4e7-ce56152fb927",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 80000\n",
            "Test size: 20000\n"
          ]
        }
      ],
      "source": [
        "# 划分训练集和测试集\n",
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train_size = int(0.8 * len(df))\n",
        "train = shuffled.take(train_size)\n",
        "test = shuffled.skip(train_size).take(len(df) - train_size)\n",
        "\n",
        "print(f\"Train size: {train_size}\")\n",
        "print(f\"Test size: {len(df) - train_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVu3rxZDlKhI"
      },
      "source": [
        "## 4. 构建双塔模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lh8xq3pXlKhI",
        "outputId": "6d85e676-7fb2-422a-e123-856e849ad4e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model classes defined\n"
          ]
        }
      ],
      "source": [
        "class UserModel(tf.keras.Model):\n",
        "    \"\"\"用户塔模型\"\"\"\n",
        "\n",
        "    def __init__(self, unique_user_ids, embedding_dim=64):\n",
        "        super().__init__()\n",
        "\n",
        "        # 用户ID嵌入\n",
        "        self.user_embedding = tf.keras.Sequential([\n",
        "            tf.keras.layers.StringLookup(\n",
        "                vocabulary=unique_user_ids,\n",
        "                mask_token=None\n",
        "            ),\n",
        "            tf.keras.layers.Embedding(\n",
        "                len(unique_user_ids) + 1,\n",
        "                embedding_dim\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        # 深度网络\n",
        "        self.dense_layers = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(128, activation='relu'),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_embedding = self.user_embedding(inputs['user_id'])\n",
        "        return self.dense_layers(user_embedding)\n",
        "\n",
        "\n",
        "class ItemModel(tf.keras.Model):\n",
        "    \"\"\"商品塔模型\"\"\"\n",
        "\n",
        "    def __init__(self, unique_item_ids, embedding_dim=64):\n",
        "        super().__init__()\n",
        "\n",
        "        # 商品ID嵌入\n",
        "        self.item_embedding = tf.keras.Sequential([\n",
        "            tf.keras.layers.StringLookup(\n",
        "                vocabulary=unique_item_ids,\n",
        "                mask_token=None\n",
        "            ),\n",
        "            tf.keras.layers.Embedding(\n",
        "                len(unique_item_ids) + 1,\n",
        "                embedding_dim\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        # 深度网络\n",
        "        self.dense_layers = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(128, activation='relu'),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        item_embedding = self.item_embedding(inputs['item_id'])\n",
        "        return self.dense_layers(item_embedding)\n",
        "\n",
        "\n",
        "class TwoTowerModel(tfrs.Model):\n",
        "    \"\"\"双塔推荐模型\"\"\"\n",
        "\n",
        "    def __init__(self, user_model, item_model, items_dataset):\n",
        "        super().__init__()\n",
        "\n",
        "        self.user_model = user_model\n",
        "        self.item_model = item_model\n",
        "\n",
        "        # 检索任务\n",
        "        self.task = tfrs.tasks.Retrieval(\n",
        "            metrics=tfrs.metrics.FactorizedTopK(\n",
        "                candidates=items_dataset.batch(128).map(\n",
        "                    lambda x: (x['item_id'], self.item_model(x))\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def compute_loss(self, features, training=False):\n",
        "        user_embeddings = self.user_model(features)\n",
        "        item_embeddings = self.item_model(features)\n",
        "        return self.task(user_embeddings, item_embeddings)\n",
        "\n",
        "print(\"Model classes defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GVfY1gtAlKhJ",
        "outputId": "fa330f5a-91e4-4b5a-dc3e-e6436ba01311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot convert '('c', 'o', 'u', 'n', 't', 'e', 'r')' to a shape. Found invalid entry 'c' of type '<class 'str'>'. ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2956396610.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 创建双塔模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwoTowerModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model created\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3263323943.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, user_model, item_model, items_dataset)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# 检索任务\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         self.task = tfrs.tasks.Retrieval(\n\u001b[0;32m---> 72\u001b[0;31m             metrics=tfrs.metrics.FactorizedTopK(\n\u001b[0m\u001b[1;32m     73\u001b[0m                 candidates=items_dataset.batch(128).map(\n\u001b[1;32m     74\u001b[0m                     \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow_recommenders/metrics/factorized_top_k.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, candidates, ks, name)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m       candidates = (\n\u001b[0;32m---> 79\u001b[0;31m           \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorized_top_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStreaming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0mindex_from_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow_recommenders/layers/factorized_top_k.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, query_model, k, handle_incomplete_batches, num_parallel_calls, sorted_order)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"counter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m   def index_from_dataset(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, shape, initializer, dtype, trainable, autocast, regularizer, constraint, aggregation, overwrite_with_gradient, name)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             variable = backend.Variable(\n\u001b[0m\u001b[1;32m    576\u001b[0m                 \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_with_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36m_validate_shape\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36mstandardize_shape\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_int_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    608\u001b[0m                 \u001b[0;34mf\"Cannot convert '{shape}' to a shape. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;34mf\"Found invalid entry '{e}' of type '{type(e)}'. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot convert '('c', 'o', 'u', 'n', 't', 'e', 'r')' to a shape. Found invalid entry 'c' of type '<class 'str'>'. "
          ]
        }
      ],
      "source": [
        "# 创建模型实例\n",
        "user_model = UserModel(unique_user_ids)\n",
        "item_model = ItemModel(unique_item_ids)\n",
        "\n",
        "# 创建商品数据集（用于候选生成）\n",
        "items_dataset = ratings.map(lambda x: {'item_id': x['item_id']})\n",
        "\n",
        "# 创建双塔模型\n",
        "model = TwoTowerModel(user_model, item_model, items_dataset)\n",
        "\n",
        "print(\"Model created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLV3uiGglKhJ"
      },
      "source": [
        "## 5. 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoAz6ZLwlKhJ"
      },
      "outputs": [],
      "source": [
        "# 编译模型\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "\n",
        "# 配置回调\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_factorized_top_k/top_100_categorical_accuracy',\n",
        "        patience=3,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath='./checkpoints/model_{epoch:02d}',\n",
        "        save_weights_only=False,\n",
        "        save_freq='epoch'\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"Model compiled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAB-5CYelKhJ"
      },
      "outputs": [],
      "source": [
        "# 训练模型\n",
        "history = model.fit(\n",
        "    train.batch(4096),\n",
        "    validation_data=test.batch(4096),\n",
        "    epochs=10,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3_ZynxBlKhJ"
      },
      "source": [
        "## 6. 评估模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEwE0JqNlKhK"
      },
      "outputs": [],
      "source": [
        "# 评估模型\n",
        "metrics = model.evaluate(test.batch(4096), return_dict=True)\n",
        "\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "for key, value in metrics.items():\n",
        "    print(f\"{key}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmA8mAN1lKhK"
      },
      "outputs": [],
      "source": [
        "# 可视化训练历史\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['factorized_top_k/top_100_categorical_accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_factorized_top_k/top_100_categorical_accuracy'], label='Val Acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Top-100 Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RXmoepplKhK"
      },
      "source": [
        "## 7. 测试推荐"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St0-0n8flKhK"
      },
      "outputs": [],
      "source": [
        "# 创建推荐索引\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
        "index.index_from_dataset(\n",
        "    items_dataset.batch(100).map(\n",
        "        lambda x: (x['item_id'], model.item_model(x))\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"Index created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Zqjg1O5lKhK"
      },
      "outputs": [],
      "source": [
        "# 为测试用户生成推荐\n",
        "test_user_id = unique_user_ids[0]\n",
        "_, recommendations = index(tf.constant([test_user_id]))\n",
        "\n",
        "print(f\"\\nTop 10 recommendations for {test_user_id}:\")\n",
        "for i, item_id in enumerate(recommendations[0, :10].numpy()):\n",
        "    print(f\"{i+1}. {item_id.decode('utf-8')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GyTULB5lKhK"
      },
      "source": [
        "## 8. 导出模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_TJ3F0QlKhK"
      },
      "outputs": [],
      "source": [
        "# 保存完整模型\n",
        "model_path = './saved_models/two_tower'\n",
        "tf.saved_model.save(model, model_path)\n",
        "print(f\"Model saved to {model_path}\")\n",
        "\n",
        "# 保存索引\n",
        "index_path = './saved_models/index'\n",
        "tf.saved_model.save(index, index_path)\n",
        "print(f\"Index saved to {index_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8Py6e0HlKhL"
      },
      "outputs": [],
      "source": [
        "# 压缩模型文件\n",
        "!zip -r saved_models.zip ./saved_models\n",
        "print(\"Model compressed to saved_models.zip\")\n",
        "print(\"\\n下载此文件并上传到 Railway 进行部署\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV53Bm2XlKhL"
      },
      "source": [
        "## 9. 下载模型\n",
        "\n",
        "运行下面的代码下载训练好的模型："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9l1EOiglKhL"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# 下载压缩的模型文件\n",
        "files.download('saved_models.zip')\n",
        "\n",
        "print(\"\\n模型已下载！\")\n",
        "print(\"\\n下一步:\")\n",
        "print(\"1. 解压 saved_models.zip\")\n",
        "print(\"2. 将 saved_models 文件夹上传到项目的 models/ 目录\")\n",
        "print(\"3. 部署到 Railway\")\n",
        "print(\"4. 测试 API: curl https://your-app.railway.app/api/recommend/user_1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aS5HMl1lKhL"
      },
      "source": [
        "## 完成！\n",
        "\n",
        "恭喜！您已经成功训练了一个 TFRS 推荐模型。\n",
        "\n",
        "### 下一步\n",
        "1. 下载训练好的模型\n",
        "2. 上传到 GitHub 仓库\n",
        "3. 在 Railway 部署\n",
        "4. 测试 API\n",
        "\n",
        "### 改进建议\n",
        "- 使用真实数据替换合成数据\n",
        "- 添加更多特征（用户年龄、商品类别等）\n",
        "- 尝试不同的模型架构\n",
        "- 调整超参数\n",
        "- 实现 A/B 测试"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}