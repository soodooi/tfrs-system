{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbA5cphAlKhB"
      },
      "source": [
        "# TFRS 推荐系统训练笔记本\n",
        "\n",
        "本笔记本用于在 Google Colab 上训练 TensorFlow Recommenders 模型\n",
        "\n",
        "## 使用步骤\n",
        "1. 在 Colab 中打开此笔记本\n",
        "2. 运行时 → 更改运行时类型 → 选择 GPU\n",
        "3. 点击 \"运行全部\"\n",
        "4. 等待训练完成（约 2-4 小时）\n",
        "5. 下载训练好的模型\n",
        "\n",
        "**注意**: 本笔记本仅用于学习和研究目的"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaidAW-KlKhE"
      },
      "source": [
        "## 1. 环境设置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVXALSpDlKhF",
        "outputId": "5d67f643-8ff3-44f5-ea68-db941a4c0da2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan 17 10:56:30 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0             26W /   70W |     110MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# 检查 GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9RAvCBhzlKhG",
        "outputId": "0b322010-f3e8-4549-a099-eb3f45c569f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.17.0\n",
            "  Downloading tensorflow-2.17.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.17.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.17.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.17.0) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.17.0) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.17.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.17.0) (3.15.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.17.0) (18.1.1)\n",
            "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow==2.17.0)\n",
            "  Downloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.17.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.17.0) (25.0)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.17.0)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.17.0) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.17.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.17.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.17.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.17.0) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.17.0) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.17.0) (1.76.0)\n",
            "Collecting tensorboard<2.18,>=2.17 (from tensorflow==2.17.0)\n",
            "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.17.0) (3.10.0)\n",
            "Collecting numpy<2.0.0,>=1.26.0 (from tensorflow==2.17.0)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow==2.17.0) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->tensorflow==2.17.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->tensorflow==2.17.0) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->tensorflow==2.17.0) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.1.5)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.2.0->tensorflow==2.17.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.2.0->tensorflow==2.17.0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow==2.17.0) (0.1.2)\n",
            "Downloading tensorflow-2.17.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.4/601.4 MB\u001b[0m \u001b[31m864.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m123.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m141.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, numpy, tensorboard, ml-dtypes, tensorflow\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.19.0\n",
            "    Uninstalling tensorboard-2.19.0:\n",
            "      Successfully uninstalled tensorboard-2.19.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml_dtypes 0.5.4\n",
            "    Uninstalling ml_dtypes-0.5.4:\n",
            "      Successfully uninstalled ml_dtypes-0.5.4\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.19.0\n",
            "    Uninstalling tensorflow-2.19.0:\n",
            "      Successfully uninstalled tensorflow-2.19.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.17.0 which is incompatible.\n",
            "tensorflow-text 2.19.0 requires tensorflow<2.20,>=2.19.0, but you have tensorflow 2.17.0 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "pytensor 2.36.3 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tensorstore 0.1.80 requires ml_dtypes>=0.5.0, but you have ml-dtypes 0.4.1 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "tf-keras 2.19.0 requires tensorflow<2.20,>=2.19, but you have tensorflow 2.17.0 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires ml_dtypes>=0.5.0, but you have ml-dtypes 0.4.1 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires ml_dtypes>=0.5.0, but you have ml-dtypes 0.4.1 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml-dtypes-0.4.1 numpy-1.26.4 protobuf-4.25.8 tensorboard-2.17.1 tensorflow-2.17.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "ml_dtypes",
                  "numpy",
                  "tensorflow"
                ]
              },
              "id": "e157b94d38b44324add216c603c3a2cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-recommenders in /usr/local/lib/python3.12/dist-packages (0.7.3)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow-recommenders) (1.4.0)\n",
            "Requirement already satisfied: tensorflow>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-recommenders) (2.17.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.15.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (4.25.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.76.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=2.9.0->tensorflow-recommenders) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->tensorflow>=2.9.0->tensorflow-recommenders) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->tensorflow>=2.9.0->tensorflow-recommenders) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->tensorflow>=2.9.0->tensorflow-recommenders) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.9.0->tensorflow-recommenders) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.9.0->tensorflow-recommenders) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.9.0->tensorflow-recommenders) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.9.0->tensorflow-recommenders) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.9.0->tensorflow-recommenders) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.9.0->tensorflow-recommenders) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.9.0->tensorflow-recommenders) (3.1.5)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow>=2.9.0->tensorflow-recommenders) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.2.0->tensorflow>=2.9.0->tensorflow-recommenders) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.2.0->tensorflow>=2.9.0->tensorflow-recommenders) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow>=2.9.0->tensorflow-recommenders) (0.1.2)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 4, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 11, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# 安装依赖\n",
        "!pip install tensorflow==2.19.0\n",
        "!pip install tensorflow-recommenders\n",
        "!pip install -q pandas numpy scikit-learn\n",
        "!pip install -q requests beautifulsoup4\n",
        "!pip install -q tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hA3TtlXylKhG"
      },
      "outputs": [],
      "source": [
        "# 导入库\n",
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, Text\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"TFRS version: {tfrs.__version__}\")\n",
        "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBA_rnCGlKhG"
      },
      "source": [
        "## 2. 数据准备\n",
        "\n",
        "### 选项 A: 使用公开数据集（推荐）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6_Y6ljnlKhH"
      },
      "outputs": [],
      "source": [
        "# 使用 MovieLens 数据集作为示例\n",
        "# 实际使用时替换为您的数据\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# 加载 MovieLens 数据集\n",
        "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
        "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
        "\n",
        "# 查看数据\n",
        "for x in ratings.take(1):\n",
        "    print(f\"User: {x['user_id']}\")\n",
        "    print(f\"Movie: {x['movie_id']}\")\n",
        "    print(f\"Rating: {x['user_rating']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqNud996lKhH"
      },
      "source": [
        "### 选项 B: 生成合成数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j7D-FY7lKhH"
      },
      "outputs": [],
      "source": [
        "# 生成合成数据用于测试\n",
        "def generate_synthetic_data(n_users=10000, n_items=1000, n_interactions=100000):\n",
        "    \"\"\"\n",
        "    生成合成推荐数据\n",
        "    \"\"\"\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # 生成用户ID（幂律分布）\n",
        "    user_ids = np.random.zipf(1.5, n_interactions) % n_users\n",
        "\n",
        "    # 生成商品ID（长尾分布）\n",
        "    item_ids = np.random.zipf(1.3, n_interactions) % n_items\n",
        "\n",
        "    # 生成评分\n",
        "    ratings = np.random.randint(1, 6, n_interactions)\n",
        "\n",
        "    # 生成时间戳\n",
        "    timestamps = np.random.randint(1640000000, 1700000000, n_interactions)\n",
        "\n",
        "    # 创建 DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'user_id': [f'user_{i}' for i in user_ids],\n",
        "        'item_id': [f'item_{i}' for i in item_ids],\n",
        "        'rating': ratings,\n",
        "        'timestamp': timestamps\n",
        "    })\n",
        "\n",
        "    return df\n",
        "\n",
        "# 生成数据\n",
        "df = generate_synthetic_data()\n",
        "print(f\"Generated {len(df)} interactions\")\n",
        "print(df.head())\n",
        "\n",
        "# 转换为 TensorFlow Dataset\n",
        "ratings = tf.data.Dataset.from_tensor_slices(dict(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A62E1Q7ClKhI"
      },
      "source": [
        "## 3. 数据预处理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfzkqF-ilKhI"
      },
      "outputs": [],
      "source": [
        "# 提取唯一的用户和商品ID\n",
        "user_ids = ratings.map(lambda x: x['user_id'])\n",
        "item_ids = ratings.map(lambda x: x['item_id'])\n",
        "\n",
        "unique_user_ids = np.unique(np.concatenate(list(user_ids.batch(1000))))\n",
        "unique_item_ids = np.unique(np.concatenate(list(item_ids.batch(1000))))\n",
        "\n",
        "print(f\"Unique users: {len(unique_user_ids)}\")\n",
        "print(f\"Unique items: {len(unique_item_ids)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A4sqYFXlKhI"
      },
      "outputs": [],
      "source": [
        "# 划分训练集和测试集\n",
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train_size = int(0.8 * len(df))\n",
        "train = shuffled.take(train_size)\n",
        "test = shuffled.skip(train_size).take(len(df) - train_size)\n",
        "\n",
        "print(f\"Train size: {train_size}\")\n",
        "print(f\"Test size: {len(df) - train_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVu3rxZDlKhI"
      },
      "source": [
        "## 4. 构建双塔模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh8xq3pXlKhI"
      },
      "outputs": [],
      "source": [
        "class UserModel(tf.keras.Model):\n",
        "    \"\"\"用户塔模型\"\"\"\n",
        "\n",
        "    def __init__(self, unique_user_ids, embedding_dim=64):\n",
        "        super().__init__()\n",
        "\n",
        "        # 用户ID嵌入\n",
        "        self.user_embedding = tf.keras.Sequential([\n",
        "            tf.keras.layers.StringLookup(\n",
        "                vocabulary=unique_user_ids,\n",
        "                mask_token=None\n",
        "            ),\n",
        "            tf.keras.layers.Embedding(\n",
        "                len(unique_user_ids) + 1,\n",
        "                embedding_dim\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        # 深度网络\n",
        "        self.dense_layers = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(128, activation='relu'),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_embedding = self.user_embedding(inputs['user_id'])\n",
        "        return self.dense_layers(user_embedding)\n",
        "\n",
        "\n",
        "class ItemModel(tf.keras.Model):\n",
        "    \"\"\"商品塔模型\"\"\"\n",
        "\n",
        "    def __init__(self, unique_item_ids, embedding_dim=64):\n",
        "        super().__init__()\n",
        "\n",
        "        # 商品ID嵌入\n",
        "        self.item_embedding = tf.keras.Sequential([\n",
        "            tf.keras.layers.StringLookup(\n",
        "                vocabulary=unique_item_ids,\n",
        "                mask_token=None\n",
        "            ),\n",
        "            tf.keras.layers.Embedding(\n",
        "                len(unique_item_ids) + 1,\n",
        "                embedding_dim\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        # 深度网络\n",
        "        self.dense_layers = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(128, activation='relu'),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        item_embedding = self.item_embedding(inputs['item_id'])\n",
        "        return self.dense_layers(item_embedding)\n",
        "\n",
        "\n",
        "class TwoTowerModel(tfrs.Model):\n",
        "    \"\"\"双塔推荐模型\"\"\"\n",
        "\n",
        "    def __init__(self, user_model, item_model, items_dataset):\n",
        "        super().__init__()\n",
        "\n",
        "        self.user_model = user_model\n",
        "        self.item_model = item_model\n",
        "\n",
        "        # 检索任务\n",
        "        self.task = tfrs.tasks.Retrieval(\n",
        "            metrics=tfrs.metrics.FactorizedTopK(\n",
        "                candidates=items_dataset.batch(128).map(\n",
        "                    lambda x: (x['item_id'], self.item_model(x))\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def compute_loss(self, features, training=False):\n",
        "        user_embeddings = self.user_model(features)\n",
        "        item_embeddings = self.item_model(features)\n",
        "        return self.task(user_embeddings, item_embeddings)\n",
        "\n",
        "print(\"Model classes defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVfY1gtAlKhJ"
      },
      "outputs": [],
      "source": [
        "# 创建模型实例\n",
        "user_model = UserModel(unique_user_ids)\n",
        "item_model = ItemModel(unique_item_ids)\n",
        "\n",
        "# 创建商品数据集（用于候选生成）\n",
        "items_dataset = ratings.map(lambda x: {'item_id': x['item_id']})\n",
        "\n",
        "# 创建双塔模型\n",
        "model = TwoTowerModel(user_model, item_model, items_dataset)\n",
        "\n",
        "print(\"Model created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLV3uiGglKhJ"
      },
      "source": [
        "## 5. 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoAz6ZLwlKhJ"
      },
      "outputs": [],
      "source": [
        "# 编译模型\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "\n",
        "# 配置回调\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_factorized_top_k/top_100_categorical_accuracy',\n",
        "        patience=3,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath='./checkpoints/model_{epoch:02d}',\n",
        "        save_weights_only=False,\n",
        "        save_freq='epoch'\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"Model compiled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAB-5CYelKhJ"
      },
      "outputs": [],
      "source": [
        "# 训练模型\n",
        "history = model.fit(\n",
        "    train.batch(4096),\n",
        "    validation_data=test.batch(4096),\n",
        "    epochs=10,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3_ZynxBlKhJ"
      },
      "source": [
        "## 6. 评估模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEwE0JqNlKhK"
      },
      "outputs": [],
      "source": [
        "# 评估模型\n",
        "metrics = model.evaluate(test.batch(4096), return_dict=True)\n",
        "\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "for key, value in metrics.items():\n",
        "    print(f\"{key}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmA8mAN1lKhK"
      },
      "outputs": [],
      "source": [
        "# 可视化训练历史\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['factorized_top_k/top_100_categorical_accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_factorized_top_k/top_100_categorical_accuracy'], label='Val Acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Top-100 Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RXmoepplKhK"
      },
      "source": [
        "## 7. 测试推荐"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St0-0n8flKhK"
      },
      "outputs": [],
      "source": [
        "# 创建推荐索引\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
        "index.index_from_dataset(\n",
        "    items_dataset.batch(100).map(\n",
        "        lambda x: (x['item_id'], model.item_model(x))\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"Index created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Zqjg1O5lKhK"
      },
      "outputs": [],
      "source": [
        "# 为测试用户生成推荐\n",
        "test_user_id = unique_user_ids[0]\n",
        "_, recommendations = index(tf.constant([test_user_id]))\n",
        "\n",
        "print(f\"\\nTop 10 recommendations for {test_user_id}:\")\n",
        "for i, item_id in enumerate(recommendations[0, :10].numpy()):\n",
        "    print(f\"{i+1}. {item_id.decode('utf-8')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GyTULB5lKhK"
      },
      "source": [
        "## 8. 导出模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_TJ3F0QlKhK"
      },
      "outputs": [],
      "source": [
        "# 保存完整模型\n",
        "model_path = './saved_models/two_tower'\n",
        "tf.saved_model.save(model, model_path)\n",
        "print(f\"Model saved to {model_path}\")\n",
        "\n",
        "# 保存索引\n",
        "index_path = './saved_models/index'\n",
        "tf.saved_model.save(index, index_path)\n",
        "print(f\"Index saved to {index_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8Py6e0HlKhL"
      },
      "outputs": [],
      "source": [
        "# 压缩模型文件\n",
        "!zip -r saved_models.zip ./saved_models\n",
        "print(\"Model compressed to saved_models.zip\")\n",
        "print(\"\\n下载此文件并上传到 Railway 进行部署\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV53Bm2XlKhL"
      },
      "source": [
        "## 9. 下载模型\n",
        "\n",
        "运行下面的代码下载训练好的模型："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9l1EOiglKhL"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# 下载压缩的模型文件\n",
        "files.download('saved_models.zip')\n",
        "\n",
        "print(\"\\n模型已下载！\")\n",
        "print(\"\\n下一步:\")\n",
        "print(\"1. 解压 saved_models.zip\")\n",
        "print(\"2. 将 saved_models 文件夹上传到项目的 models/ 目录\")\n",
        "print(\"3. 部署到 Railway\")\n",
        "print(\"4. 测试 API: curl https://your-app.railway.app/api/recommend/user_1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aS5HMl1lKhL"
      },
      "source": [
        "## 完成！\n",
        "\n",
        "恭喜！您已经成功训练了一个 TFRS 推荐模型。\n",
        "\n",
        "### 下一步\n",
        "1. 下载训练好的模型\n",
        "2. 上传到 GitHub 仓库\n",
        "3. 在 Railway 部署\n",
        "4. 测试 API\n",
        "\n",
        "### 改进建议\n",
        "- 使用真实数据替换合成数据\n",
        "- 添加更多特征（用户年龄、商品类别等）\n",
        "- 尝试不同的模型架构\n",
        "- 调整超参数\n",
        "- 实现 A/B 测试"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}